# ML System Design Doc - [RU]
## Дизайн ML системы - ScientificPaper-IR v0.1.0

### 0. Термины
> `связанная информация` - последовательность фраз / блоков текста, имеющих логическую связь: например, в потенциально сравнении древних цивилазций пары `Финикия - 1200-332 г. до н. э.`, `Цивилизация Ольмеков - 1200-401 г. н. э.` и `Цивилизация Хеттов - 1600-1178 г. до н. э.` будут являться такой информацией.
> 
> `общая информация (abstract)` - краткая выжимка научной статьи / её основные концепции.
>
> `работа на локальных мощностях` - объединение двух возможных вариантов работы: на устройстве (без доступа в интернет), а также в браузере с учетом запуска бэкенда на серверах компании.

### 1. Цели и предпосылки
#### 1.1. Зачем идем в разработку продукта?

- **Бизнес-цель:**
    Создание системы для автоматического извлечения ключевой информации из научных pdf-документов, что позволяет ускорить процесс анализа научных статей и внедрение концепций, изложенных в нх, в продукты компании.

- **Почему станет лучше:**
    В отличие от существующих решений, которые предлагают исключительно извлечение таблиц, система будет поддерживать извлечение данных из графиков и схем, а также связанной и общей информации. Всё будет работать локально, позволяя обрабатывать закрытые разработки компании.

- **Что будем считать успехом:**
    Успехом будет считаться достижение определенных метрик качества:
  - Точность совпадения табличных данных ≥ 90%.
  - Точность извлеченных данных из нетабличных источников информации ≥ 85%.
  - Снижение среднего времени работы со статьями.

#### 1.2. Бизнес-требования и ограничения

- **Краткое описание требований:**
    Система должна обеспечивать быстроту высокую точность извлечения данных из таблиц и графиков из файлов в формате PDF. Система должна уметь работать с данным PDF в различном формате: текстовом и графическом.

- **Бизнес-ограничения:**
     - Поддержка научных PDF-документов на русском языке.
     - Ограничения по времени обработки документа: не более 10 секунд на документ среднего размера (10–15 страниц).
     - Извлечение должно производится в md формат.
     - Минимальные требования к запуску на устройстве:
        - Nvidia GeForce GTX 1650
        - Intel Core i7 12 gen
        - 32 Gb RAM
        - **или**
        - Apple M2
        - 32 Gb RAM

> Ввиду отсутствия больших обучающих мощностей (они могут меняться по ходу разработки) и наличие выделенного времени на разработку (свыше 6 месяцев) допускается снижение метрик качества для запуска пилота.
>
> Пилот должен быть выпущен не позднее чем через **2 месяца** после начала разработки.

- **Что мы ожидаем от конкретной итерации:**
    Демо-стенд с реализованной логикой по извлечению информации и отчетами по эфеективности и точности работы системы.

- **Описание бизнес-процесса пилота:**
    1. Пользователь загружает PDF-документ.
    2. Система анализирует документ, извлекая таблицы и информацию из графиков.
    3. Выводятся структурированные результаты в виде файлом md.
    4. Пользователь проверяет корректность результатов и оставляет отзывы, если требуется.

- **Что считаем успешным пилотом:**
    - Точность извлечения таблиц и графиков ≥ 75%.
    - Скорость обработки PDF-документов ≤ 5 секунд на одну страницу.
    - Высокая устойчивость системы к нестандартным форматам таблиц и графиков.
    
- **Возможные пути развития проекта:**
    - Поддержка дополнительных языков документов.
    - Извлечение данных в иные форматы (csv, python код для создания графиков).
    - Поддержка анализа сетевых графиков и других сложных визуализаций.
    - Разработка мобильной версии для работы с документами.
    - Введение функционала отслеживания связанных исследований (через другой проект компании).
    - Создания системы тунелирования и развертывания на серверах компании для предоставления доступа другим бизнесам продукту.
    - Иные пути, согласованы с Заказчиком по результатам Пилота.

#### 1.3. Что входит в скоуп проекта/итерации, что не входит
- **Входит в скоуп:**
    - Предоставляет результатов в формате Markdown.
    - Извлечение данных из таблиц, графиков и рисунков.
    - Локальная работа без подключения к интернету.

- **Не входит в скоуп:**
    - Интерфейс (frontend) для взаимодействия с системой.
    - Извлечение глобавльной информации из текста (`связанная информация` и `общая информация`)
    - Возможность запуска на серверных мощностях компании.
    - Анализ сетевых графиков и других сложных визуализаций.
    - Поддержка русского языка (основная часть статей написано на английском, поэтому от русского на данном этапе стоит отказаться).
  
- **Качество кода и воспроизводимость:**
    - Код должен быть покрытым тестами (не менее 50% покрытия), с воспроизводимой настройкой окружения и зависимостей.
    - Код должен соответвовать настройкам форматеров, указанным в репозитории проекта.

- **Технический долг:**
    - Некоторые оптимизации производительности будут отложены до следующей итерации, как и полное покрытие тестами.
    - Поддержка сложных нестандартных PDF-форматов.

#### 1.4. Предпосылки решения

**Общие:**
- Рост объема научных публикаций и данных требующих автоматизированный анализ.
- Появление библиотек, способных производить необходимое обработки без больших вычислительных ресурсов.

**Для решения задачи необходимо:**
1. **От Заказчика:**
   - Предоставить выборку научных PDF-документов для тестирования (не менее 50 документов).
   - Указать приоритетные типы графиков, таблиц и схем для извлечения.
   - Предоставить разметку указанных данных
   - Предоставить описание формата, для извлечения графиков (код / текст с графиков)

1. **От ML-инженера:**
   - Выбор существующих моделей для обработки текста (LLaMA, BERT) и изображений (ResNet, YOLO, SVTR).
   - Посик информации о возможынх методах эффектиыной блочной разметке.
   - Поиск информации об эффективном представлении визуальных данных для наиболее точного ответа RAG-системы.
   - Информация о существующих SotA подходах для реализации RAG+OCR-систем, с учетом визуальной информации.

---

### 2. Методология

#### 2.1. Постановка задачи
Для реализации системы нужно решить следующие основные задачи:
- Для экрастрактинга информации из графических источников:
  1. Авто-маркирование облостей таблиц и графиков
  2. Извлечение из выделенных областей нужной информации
  3. формирование md версии извлечённой ифнормации
- Для экрастрактинга информации из текстовых источников:
   1. Определение ключевых концепций статьи (abstract).
   1. Обнаружение связанных блоков текста (связанных данных).

#### 2.2. Блок-схема решения

![block-schema](artifacts/block-schema.png)

#### 2.3. Этапы решения задачи

*Этап 1 - Исследование и подготовка данных.*

Цель:
- Определить список используемых датасетов:
    - Понять, какие должны быть предикторы / таргеты у каждого из необходимых датасетов.
    - Анализ доступных датасетов для каждой из категорий прошлого пункта.
    - Создание описания их структуры (формат данных, объем, качество)
- Определить формат хранения данных:
    - Создание шаблонов, описывающих структуру хранения.
    - Определения формата экстракции графических данных (при правильном подходе, качество RAG-системы заметно выше).
    - Определить подход к загрузке и обработке данных (Just-in-time / Preprocessing).
- Разбить данные на тренеровочную выборку, тестовую и валидационную (в случае fine-tunning, распределение - 33 / 33 / 33, в случае обучения с нуля - 70 / 20 / 10)

Таблица с используемыми датасетами:

| Название датасета  | Тип | Описание | Ссылка |
| ------------- | ------------- | ------------- | ------------- |
| ChartQA  | OCR графиков  | ... | [link](https://github.com/vis-nlp/ChartQA/tree/main) |
| PubTable-1M  | OCR таблиц  | ... | [link](https://huggingface.co/datasets/bsmock/pubtables-1m) |
| DocLayNet  | Разметка документов  | ... | [link](https://huggingface.co/datasets/ds4sd/DocLayNet) |
| SciQAG  | Генератор Q&A для документов о их содержании  | ... | [link](https://github.com/MasterAI-EAM/SciQAG) |
| arXiv Dataset  | Научные сататьи  | ... | [link](https://www.kaggle.com/datasets/Cornell-University/arxiv) |
| NLP and LLM related Arxiv papers  | Научные сататьи  | ... | [link](https://www.kaggle.com/datasets/harshsinghal/nlp-and-llm-related-arxiv-papers) |

Особенности данных:
- Feature Engineering не применим в силу отсутствия доступных для исследования фичей (на вход подается только документ или картинка)

Ожидаемый результат:
- Графические данные отчищены от неотносящихся к ним марок.
- Набор датасетов, распределенный по директориям по типу задач, а также сопровадетльная информация в виде таблиц в формате CSV для хранения предикторов.
- Два датасета для:
    - Baseline - практически или вовсе нет train-а; датасет урезан до ~0k сэмплов; добавлены аугментационные данные (графики вставлены в рандомные места статьи).
    - MVP - полный набор данных (дез аугментации); для графических данных в статьях выболнена процедура OCR через Baseline.

Риски:
- Набор графиков включает в себя лишь три типа графиков: Line Chart, Pie Chart и Bar Chart. Нет графиков для теоретических значений (возможно, эти графики стоит сгенерировать самостоятельно).
- Структурное отличие данных в датасетах от статей компании (использовать статьи компании можно только для валидации, и то, в оцень небольшом объеме: самих статей довольно мало ~100 штук).

 *Этап 2 - Обработка данных-документов для извлечения информации из графических данных*
 
Цель: Доразметить данные для дальнейшего обучения итоговых моделей и проверки качества их работы и заменить исходные датасеты на один, полностью соотвествующий изначальной задаче.

Ожидаемый результат:
- Для статей из датасета будут добавлена разметка layout-а, данные графиков и таблиц в текстовом виде.
- Изначальные данные других категорий (не RAG над статьями) заменены на доразмеченные.

Риски:
- Разметка может получиться некачественной, в силу отсуствия каких-либо элементов маркирования, в следвие чего может поыпаться и вся остальная доразметка.
- Классы для меток в layout, а также типов графиков могут перестать быть сбалансированными из-за чего итоговая модель может недоучиться на малопредставленных классах, что может плохо сказаться на итоговом качестве системы.

Замечание:
- Данные могут быть доразмечены и после этапа 3 при помощи Baseline

 ***Этап 3 - Разработка базовой модели***

Цель: Выбрать модели и составить архитектуру для базового решения задачи, которое будет удовлетворять пониженным условиям скорости работы (~5 секунд на запрос) и пониженным метрикам качества.

В качестве базовой модели была выбрана [Llama 3.2 Multimodal](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/) (для обработки запросов о содержании документа и извлечения данных из картинки). 
 
 ***Этап 4 - Интерпретация результатов и согласование с заказчиком***
 
Цель:
- Представить полученные результаты бизнесу:
    - Выяснить, являются ли текщие результаты приемлимыми и стоит ли разрабатывать MVP (или достаточно использовать Baseline)
    - Установление точности в новых метриках для конечной модели.

Подход:
- Демонстрация положительных и отрицательных примеров работы системы: правильно извлеченные данные из статьи заявки, ошибки модели.
- Выбор и демонстрация метрики качества:
    - Для численных данных будем использовать метрику $R_2$.
    - Для строчных ответов будем использовать метрику $F_1$.
    - Для RAG создадим эмбеддинги реального и сгенерированного ответа (будем испольовать [mini-lm](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)). Между ответами посчитаем среднее косинусное расстояние (Ожидаемая точность не меньше 70%). 
- Обсудить проблемы: время инференса, допустимость представленных ошибок, используемые ресурсы.

Ожидаемый результат:
- Бизнес убеждается, что проект имеет потенциал и согласовывает дальнейшие этапы на разработку MVP.
- Будут уточнены требования к данным и результам самой модели.

Риски:
- Baseline может оказаться слишком сильным и полностью закрыть потребности бизнеса.
 
 ***Этап 5 - Разработка и оценка MVP модели***
 
![architecture](artifacts/MVPArchitecture.png)

*(архитектура взаимодействия с проектом | архитектура основана на статьях [1](https://arxiv.org/pdf/2210.02830) и [2](https://arxiv.org/pdf/2409.18839))*

Для архитектуры были выбраны следующие модели:
    - Разметка - [DETR-layout-detection](https://huggingface.co/cmarkea/detr-layout-detection) 
    - Экстракция информации из картинок - [mPLUG-DocOwl 1.5](https://arxiv.org/pdf/2403.12895)
    - Основная модель общения - [Llama 3.2 Multimodal](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/)
 
 ***Этап 6 - Интерпретация моделей***  

Цель:
- Создать интерпретатора для объяснения предсказаний
- Выявить, на какие данные модель обращает внимание (а на что вообще не смотрит):
    -  Проверить использование графической информации итоговой моделью
  
Риски:
- Полученная модель может полностью игнорировать графическую информацию и фокусировать лишь на тексте, что приведт её к неспособности выдавать точные ответы в отношении вопросов про графические данные.

 ***Этап 7 - Подготовка финального отчета для бизнеса и согласовании дальнейших планов развития***

![prototype-interface](artifacts/PrototypeAlpha.png)

*(в случае достаточного количества ресурсов, будет создан предварительный графический интерфейс)*
 
Цель:
- Сформировать финальный отчёт и презентацию для бизнеса:
    -  Продемонстрировать работу MVP на данных компании
    -  Сравнить работу с Baseline: на проблемные места каждой из итераций, сравнить метрики
- Представить полученные результаты бизнесу:
    - Обосновать целесообразность внедрения составленного решения
    - Согласовать план дальнейшего расширения функционал
- Согласование перехода к пилоту

Ожидаемый результат:
- Итоговый отчёт, подтверждающий достижение бизнес-целей.
- Бизнес одобряет дальнейший запуск пилота и стратегию развития проекта (например, выход за пределы компании и стонавление отдельным продуктом).

---
  
> ### Материалы для дополнительного погружения в тему
> - [Подход для OCR научных статей](https://arxiv.org/abs/2210.02830)
> - [Алгоритмическое извлечение таблиц](https://pypi.org/project/tabula-py/)
> - [ML подход для извлечения данных на основе собственной модели](https://github.com/Filimoa/open-parse/tree/main)
> - [ML подход для извлечения данных на основе zero-shot gpt-mini](https://github.com/getomni-ai/zerox?tab=readme-ov-file), а также другие модели [aws](https://aws.amazon.com/textract/pricing/#:~:text=Amazon%20Textract%20API%20pricing), [google](https://cloud.google.com/document-ai/pricing), [azure](https://azure.microsoft.com/en-us/pricing/details/ai-document-intelligence/) и [evaluation разных LLM](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation)
> - Конференция, посвященная работе с документами и их распознаванию - [ICDAR 2024 Proceedings](https://icdar2024.net/procceedings/)
> - [SotA подход для RAG систем](https://arxiv.org/pdf/2409.18839) для работы с документами сложной разметки (с заголовками, колонтитулами, формулами)
> - [Лекция LlamaIndex Webinar](https://www.youtube.com/watch?v=nzcBvba7mzI) об эффективном извлечении информации с помощью визуальных моделей.
> - [mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding](https://arxiv.org/pdf/2403.12895)
